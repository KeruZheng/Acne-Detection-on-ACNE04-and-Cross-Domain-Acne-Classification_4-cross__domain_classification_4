{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# select random 20 sample from dermnet\n",
    "### prepare pesudo test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo test list saved to /data_lg/keru/project/part2/DermNet/pseudo_eval/pseudo_test_list.txt\n",
      "Acne: 10, Non-Acne: 10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# === 配置 ===\n",
    "train_root = \"/data_lg/keru/project/part2/DermNet/train\"\n",
    "output_txt = \"/data_lg/keru/project/part2/DermNet/pseudo_eval/pseudo_test_list.txt\"\n",
    "\n",
    "num_total = 20      # 总数\n",
    "num_acne = 10        # Acne 样本数\n",
    "num_non_acne = num_total - num_acne\n",
    "\n",
    "# === 找到所有子文件夹 ===\n",
    "all_classes = [\n",
    "    d for d in os.listdir(train_root)\n",
    "    if os.path.isdir(os.path.join(train_root, d))\n",
    "]\n",
    "\n",
    "# Acne 类和 Non-Acne 类分开\n",
    "acne_folders = [d for d in all_classes if \"acne\" in d.lower()]\n",
    "non_acne_folders = [d for d in all_classes if d not in acne_folders]\n",
    "\n",
    "assert acne_folders, \"没有找到包含 'acne' 的文件夹！\"\n",
    "\n",
    "# === 随机选 Acne 样本 ===\n",
    "acne_samples = []\n",
    "for folder in acne_folders:\n",
    "    folder_path = os.path.join(train_root, folder)\n",
    "    imgs = [os.path.join(folder_path, f) for f in os.listdir(folder_path)\n",
    "            if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "    acne_samples.extend(imgs)\n",
    "pseudo_acne = random.sample(acne_samples, num_acne)\n",
    "\n",
    "# === 随机选 Non-Acne 样本（保证尽量不同文件夹）===\n",
    "pseudo_non_acne = []\n",
    "selected_folders = random.sample(non_acne_folders, min(num_non_acne, len(non_acne_folders)))\n",
    "for folder in selected_folders:\n",
    "    folder_path = os.path.join(train_root, folder)\n",
    "    imgs = [os.path.join(folder_path, f) for f in os.listdir(folder_path)\n",
    "            if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "    if imgs:\n",
    "        pseudo_non_acne.append(random.choice(imgs))\n",
    "\n",
    "# 若文件夹不够，继续补\n",
    "while len(pseudo_non_acne) < num_non_acne:\n",
    "    folder = random.choice(non_acne_folders)\n",
    "    folder_path = os.path.join(train_root, folder)\n",
    "    imgs = [os.path.join(folder_path, f) for f in os.listdir(folder_path)\n",
    "            if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "    if imgs:\n",
    "        pseudo_non_acne.append(random.choice(imgs))\n",
    "\n",
    "# === 合并 & 保存 txt ===\n",
    "with open(output_txt, \"w\") as f:\n",
    "    for p in pseudo_acne:\n",
    "        f.write(f\"{p}\\t1\\n\")\n",
    "    for p in pseudo_non_acne:\n",
    "        f.write(f\"{p}\\t0\\n\")\n",
    "\n",
    "print(f\"Pseudo test list saved to {output_txt}\")\n",
    "print(f\"Acne: {len(pseudo_acne)}, Non-Acne: {len(pseudo_non_acne)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_pseudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data_ft_8/keru/conda/envs/yolov5/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/data_ft_8/keru/conda/envs/yolov5/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 20/20 [00:01<00:00, 16.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Grad-CAM saved to /data_lg/keru/project/part2/DermNet/pseudo_eval/gradcam_pseudo\n",
      "Accuracy: 0.5000\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "AUROC: 0.1300\n",
      "📄 Metrics and prediction records saved to: /data_lg/keru/project/part2/DermNet/pseudo_eval/pseudo_eval_metrics.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/data_ft_8/keru/conda/envs/yolov5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import transforms, models\n",
    "from torch import nn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "import json\n",
    "\n",
    "# === 配置 ===\n",
    "pseudo_txt = \"/data_lg/keru/project/part2/DermNet/pseudo_eval/pseudo_test_list.txt\"\n",
    "model_path = \"/data_lg/keru/project/part2/outputs/best_resnet50.pt\"\n",
    "gradcam_dir = \"/data_lg/keru/project/part2/DermNet/pseudo_eval/gradcam_pseudo\"\n",
    "\n",
    "os.makedirs(gradcam_dir, exist_ok=True)\n",
    "\n",
    "# === 加载模型 ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet50(pretrained=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# === 预处理 ===\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# === 读取伪测试集列表 ===\n",
    "samples = []\n",
    "labels = []\n",
    "with open(pseudo_txt) as f:\n",
    "    for line in f:\n",
    "        path, lbl = line.strip().split(\"\\t\")\n",
    "        samples.append(path)\n",
    "        labels.append(int(lbl))\n",
    "\n",
    "# === Grad-CAM 设置 ===\n",
    "target_layer = model.layer4[-1]\n",
    "cam = GradCAM(model=model, target_layers=[target_layer])\n",
    "\n",
    "# === 推理 ===\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "\n",
    "for img_path, true_label in tqdm(zip(samples, labels), total=len(samples)):\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    input_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        prob = torch.softmax(output, dim=1)[0, 1].item()\n",
    "        pred = output.argmax(dim=1).cpu().item()\n",
    "\n",
    "    all_preds.append(pred)\n",
    "    all_probs.append(prob)\n",
    "\n",
    "    # === Grad-CAM 可视化 ===\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, targets=[ClassifierOutputTarget(1)])[0, :]\n",
    "    rgb_img = transform(img).permute(1, 2, 0).cpu().numpy()\n",
    "    rgb_img = (rgb_img - rgb_img.min()) / (rgb_img.max() - rgb_img.min())\n",
    "    cam_image = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "    out_name = os.path.basename(img_path).split(\".\")[0] + \"_gradcam.jpg\"\n",
    "    out_path = os.path.join(gradcam_dir, out_name)\n",
    "    Image.fromarray(cam_image).save(out_path)\n",
    "\n",
    "print(f\"✅ Grad-CAM saved to {gradcam_dir}\")\n",
    "\n",
    "# === 计算指标 ===\n",
    "acc = accuracy_score(labels, all_preds)\n",
    "prec = precision_score(labels, all_preds)\n",
    "rec = recall_score(labels, all_preds)\n",
    "f1 = f1_score(labels, all_preds)\n",
    "try:\n",
    "    auc = roc_auc_score(labels, all_probs)\n",
    "except:\n",
    "    auc = float('nan')\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"AUROC: {auc:.4f}\")\n",
    "\n",
    "import json\n",
    "import os\n",
    "# === 保存详细预测信息和整体评估指标 ===\n",
    "results = []\n",
    "for path, true_label, pred, prob in zip(samples, labels, all_preds, all_probs):\n",
    "    results.append({\n",
    "        \"image\": path,\n",
    "        \"true_label\": true_label,\n",
    "        \"pred_label\": pred,\n",
    "        \"probability\": round(prob, 4),\n",
    "        \"correct\": int(pred == true_label)\n",
    "    })\n",
    "\n",
    "metrics = {\n",
    "    \"results\": results,\n",
    "    \"summary\": {\n",
    "        \"accuracy\": round(acc, 4),\n",
    "        \"precision\": round(prec, 4),\n",
    "        \"recall\": round(rec, 4),\n",
    "        \"f1_score\": round(f1, 4),\n",
    "        \"auroc\": round(auc, 4)\n",
    "    }\n",
    "}\n",
    "\n",
    "save_path = \"/data_lg/keru/project/part2/DermNet/pseudo_eval/pseudo_eval_metrics.json\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(metrics, f, indent=4)\n",
    "\n",
    "print(f\"📄 Metrics and prediction records saved to: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 13.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Grad-CAM saved to: /data_lg/keru/project/part2/DermNet/pseudo_eval/gradcam_v2_weight\n",
      "\n",
      "🎯 Evaluation Metrics:\n",
      "Accuracy:  0.5000\n",
      "Precision: 0.0000\n",
      "Recall:    0.0000\n",
      "F1 Score:  0.0000\n",
      "AUROC:     0.4400\n",
      "\n",
      "📊 Metrics saved to: /data_lg/keru/project/part2/DermNet/pseudo_eval/pseudo_eval_metrics.json\n",
      "📝 Per-image results saved to: /data_lg/keru/project/part2/DermNet/pseudo_eval/pseudo_eval_records.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/data_ft_8/keru/conda/envs/yolov5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "import json\n",
    "\n",
    "# === 配置 ===\n",
    "pseudo_txt = \"/data_lg/keru/project/part2/DermNet/pseudo_eval/pseudo_test_list.txt\"\n",
    "model_path = \"/data_lg/keru/project/part2/outputs_v2_weight/best_facenet_v2.pt\"  # ← 改为你 v2/v3 模型路径\n",
    "gradcam_dir = \"/data_lg/keru/project/part2/DermNet/pseudo_eval/gradcam_v2_weight\"\n",
    "\n",
    "os.makedirs(gradcam_dir, exist_ok=True)\n",
    "\n",
    "# === 模型加载（处理 module.） ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = InceptionResnetV1(pretrained='vggface2', classify=True, num_classes=2)\n",
    "\n",
    "state_dict = torch.load(model_path, map_location=device)\n",
    "new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "model.load_state_dict(new_state_dict)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# === 预处理 ===\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# === 读取伪测试集列表 ===\n",
    "samples, labels = [], []\n",
    "with open(pseudo_txt) as f:\n",
    "    for line in f:\n",
    "        path, lbl = line.strip().split(\"\\t\")\n",
    "        samples.append(path)\n",
    "        labels.append(int(lbl))\n",
    "\n",
    "# === Grad-CAM 设置 ===\n",
    "target_layer = model.block8.branch1[-1]  # 最后卷积\n",
    "cam = GradCAM(model=model, target_layers=[target_layer])\n",
    "\n",
    "# === 推理 ===\n",
    "all_preds, all_probs, json_records = [], [], []\n",
    "\n",
    "for img_path, true_label in tqdm(zip(samples, labels), total=len(samples)):\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    input_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        prob = torch.softmax(output, dim=1)[0, 1].item()\n",
    "        pred = output.argmax(dim=1).item()\n",
    "\n",
    "    all_preds.append(pred)\n",
    "    all_probs.append(prob)\n",
    "\n",
    "    # Grad-CAM\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, targets=[ClassifierOutputTarget(1)])[0, :]\n",
    "    rgb_img = transform(img).permute(1, 2, 0).cpu().numpy()\n",
    "    rgb_img = (rgb_img - rgb_img.min()) / (rgb_img.max() - rgb_img.min())\n",
    "    cam_image = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "    out_name = os.path.basename(img_path).split(\".\")[0] + \"_gradcam.jpg\"\n",
    "    out_path = os.path.join(gradcam_dir, out_name)\n",
    "    Image.fromarray(cam_image).save(out_path)\n",
    "\n",
    "    json_records.append({\n",
    "        \"img\": img_path,\n",
    "        \"true\": int(true_label),\n",
    "        \"pred\": int(pred),\n",
    "        \"prob\": round(prob, 4),\n",
    "        \"correct\": int(pred == int(true_label))\n",
    "    })\n",
    "\n",
    "print(f\"\\n✅ Grad-CAM saved to: {gradcam_dir}\")\n",
    "\n",
    "# === 计算指标 ===\n",
    "acc = accuracy_score(labels, all_preds)\n",
    "prec = precision_score(labels, all_preds)\n",
    "rec = recall_score(labels, all_preds)\n",
    "f1 = f1_score(labels, all_preds)\n",
    "try:\n",
    "    auc = roc_auc_score(labels, all_probs)\n",
    "except:\n",
    "    auc = float('nan')\n",
    "\n",
    "print(\"\\n🎯 Evaluation Metrics:\")\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"AUROC:     {auc:.4f}\")\n",
    "\n",
    "# === 保存 JSON 结果 ===\n",
    "eval_dir = \"/data_lg/keru/project/part2/DermNet/pseudo_eval\"\n",
    "os.makedirs(eval_dir, exist_ok=True)\n",
    "\n",
    "metrics_path = os.path.join(eval_dir, \"pseudo_eval_metrics.json\")\n",
    "records_path = os.path.join(eval_dir, \"pseudo_eval_records.json\")\n",
    "\n",
    "with open(metrics_path, \"w\") as f:\n",
    "    json.dump({\n",
    "        \"Accuracy\": round(acc, 4),\n",
    "        \"Precision\": round(prec, 4),\n",
    "        \"Recall\": round(rec, 4),\n",
    "        \"F1 Score\": round(f1, 4),\n",
    "        \"AUROC\": round(auc, 4)\n",
    "    }, f, indent=4)\n",
    "\n",
    "with open(records_path, \"w\") as f:\n",
    "    json.dump(json_records, f, indent=4)\n",
    "\n",
    "print(f\"\\n📊 Metrics saved to: {metrics_path}\")\n",
    "print(f\"📝 Per-image results saved to: {records_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL TEST!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## real ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo test list saved to /data_lg/keru/project/part2/DermNet/eval/final_test_list.txt\n",
      "Acne: 312, Non-Acne: 3690\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# === 配置 ===\n",
    "train_root = \"/data_lg/keru/project/part2/DermNet/test\"\n",
    "output_txt = \"/data_lg/keru/project/part2/DermNet/eval/final_test_list.txt\"\n",
    "\n",
    "# === 找到所有子文件夹 ===\n",
    "all_classes = [\n",
    "    d for d in os.listdir(train_root)\n",
    "    if os.path.isdir(os.path.join(train_root, d))\n",
    "]\n",
    "\n",
    "# Acne 类和 Non-Acne 类分开\n",
    "acne_folders = [d for d in all_classes if \"acne\" in d.lower()]\n",
    "non_acne_folders = [d for d in all_classes if d not in acne_folders]\n",
    "\n",
    "assert acne_folders, \"没有找到包含 'acne' 的文件夹！\"\n",
    "\n",
    "# === 收集所有 Acne 样本 ===\n",
    "acne_samples = []\n",
    "for folder in acne_folders:\n",
    "    folder_path = os.path.join(train_root, folder)\n",
    "    imgs = [os.path.join(folder_path, f) for f in os.listdir(folder_path)\n",
    "            if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "    acne_samples.extend(imgs)\n",
    "\n",
    "# === 收集所有 Non-Acne 样本 ===\n",
    "non_acne_samples = []\n",
    "for folder in non_acne_folders:\n",
    "    folder_path = os.path.join(train_root, folder)\n",
    "    imgs = [os.path.join(folder_path, f) for f in os.listdir(folder_path)\n",
    "            if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "    non_acne_samples.extend(imgs)\n",
    "\n",
    "# === 合并 & 保存 txt ===\n",
    "with open(output_txt, \"w\") as f:\n",
    "    for p in acne_samples:\n",
    "        f.write(f\"{p}\\t1\\n\")\n",
    "    for p in non_acne_samples:\n",
    "        f.write(f\"{p}\\t0\\n\")\n",
    "\n",
    "print(f\"Pseudo test list saved to {output_txt}\")\n",
    "print(f\"Acne: {len(acne_samples)}, Non-Acne: {len(non_acne_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4002/4002 [01:15<00:00, 53.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Grad-CAM saved to: /data_lg/keru/project/part2/DermNet/eval_real/eval_cyclegan\n",
      "   正确样本: 7 张\n",
      "   错误样本: 7 张\n",
      "\n",
      "🎯 Evaluation Metrics:\n",
      "Accuracy:  0.6794\n",
      "Precision: 0.1100\n",
      "Recall:    0.4391\n",
      "F1 Score:  0.1760\n",
      "AUROC:     0.6206\n",
      "\n",
      "📊 Metrics saved to: /data_lg/keru/project/part2/DermNet/eval_real/eval_cyclegan/eval_metrics.json\n",
      "📝 Per-image results saved to: /data_lg/keru/project/part2/DermNet/eval_real/eval_cyclegan/eval_records.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "import json\n",
    "import random\n",
    "\n",
    "# === 配置 ===\n",
    "# pseudo_txt = \"/data_lg/keru/project/part2/DermNet/eval/final_test_list.txt\" #真实比例\n",
    "pseudo_txt = \"/data_lg/keru/project/part2/DermNet/eval_real/final_test_list.txt\"\n",
    "model_path = \"/data_lg/keru/project/part2/output/output_cycleGAN/best_facenet_v2.pt\"  # ← 改为你 v2/v3 模型路径\n",
    "gradcam_dir = \"/data_lg/keru/project/part2/DermNet/eval_real/eval_cyclegan\"\n",
    "eval_dir = \"/data_lg/keru/project/part2/DermNet/eval_real/eval_cyclegan\"\n",
    "os.makedirs(eval_dir, exist_ok=True)\n",
    "os.makedirs(gradcam_dir, exist_ok=True)\n",
    "\n",
    "# === 模型加载（处理 module.） ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = InceptionResnetV1(pretrained='vggface2', classify=True, num_classes=2)\n",
    "\n",
    "state_dict = torch.load(model_path, map_location=device)\n",
    "new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "model.load_state_dict(new_state_dict)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# === 预处理 ===\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# === 读取伪测试集列表 ===\n",
    "samples, labels = [], []\n",
    "with open(pseudo_txt) as f:\n",
    "    for line in f:\n",
    "        path, lbl = line.strip().split(\"\\t\")\n",
    "        samples.append(path)\n",
    "        labels.append(int(lbl))\n",
    "\n",
    "# === Grad-CAM 设置 ===\n",
    "target_layer = model.block8.branch1[-1]  # 最后卷积\n",
    "cam = GradCAM(model=model, target_layers=[target_layer])\n",
    "\n",
    "# === 推理 ===\n",
    "all_preds, all_probs, json_records = [], [], []\n",
    "correct_samples = []\n",
    "wrong_samples = []\n",
    "\n",
    "for img_path, true_label in tqdm(zip(samples, labels), total=len(samples)):\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    input_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        prob = torch.softmax(output, dim=1)[0, 1].item()\n",
    "        pred = output.argmax(dim=1).item()\n",
    "\n",
    "    all_preds.append(pred)\n",
    "    all_probs.append(prob)\n",
    "    is_correct = (pred == true_label)\n",
    "    \n",
    "    # 保存样本路径、预测结果和真实标签\n",
    "    sample_info = {\n",
    "        \"img_path\": img_path,\n",
    "        \"true_label\": true_label,\n",
    "        \"pred\": pred,\n",
    "        \"prob\": prob,\n",
    "        \"is_correct\": is_correct\n",
    "    }\n",
    "    \n",
    "    if is_correct:\n",
    "        correct_samples.append(sample_info)\n",
    "    else:\n",
    "        wrong_samples.append(sample_info)\n",
    "\n",
    "    json_records.append({\n",
    "        \"img\": img_path,\n",
    "        \"true\": int(true_label),\n",
    "        \"pred\": int(pred),\n",
    "        \"prob\": round(prob, 4),\n",
    "        \"correct\": int(is_correct)\n",
    "    })\n",
    "\n",
    "# === 随机选择7张正确和7张错误的样本 ===\n",
    "selected_correct = random.sample(correct_samples, min(7, len(correct_samples)))\n",
    "selected_wrong = random.sample(wrong_samples, min(7, len(wrong_samples)))\n",
    "selected_samples = selected_correct + selected_wrong\n",
    "\n",
    "# === 为选中的样本生成并保存Grad-CAM ===\n",
    "for i, sample in enumerate(selected_samples):\n",
    "    img = Image.open(sample[\"img_path\"]).convert(\"RGB\")\n",
    "    input_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    \n",
    "    # 生成Grad-CAM\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, targets=[ClassifierOutputTarget(1)])[0, :]\n",
    "    rgb_img = transform(img).permute(1, 2, 0).cpu().numpy()\n",
    "    rgb_img = (rgb_img - rgb_img.min()) / (rgb_img.max() - rgb_img.min())\n",
    "    cam_image = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "    \n",
    "    # 确定输出文件名和路径\n",
    "    result_type = \"correct\" if sample[\"is_correct\"] else \"wrong\"\n",
    "    img_name = os.path.basename(sample[\"img_path\"]).split(\".\")[0]\n",
    "    out_name = f\"{result_type}_{i+1}_{img_name}_gradcam.jpg\"\n",
    "    out_path = os.path.join(gradcam_dir, out_name)\n",
    "    \n",
    "    # 保存Grad-CAM图像\n",
    "    Image.fromarray(cam_image).save(out_path)\n",
    "\n",
    "print(f\"\\n✅ Grad-CAM saved to: {gradcam_dir}\")\n",
    "print(f\"   正确样本: {len(selected_correct)} 张\")\n",
    "print(f\"   错误样本: {len(selected_wrong)} 张\")\n",
    "\n",
    "# === 计算指标 ===\n",
    "acc = accuracy_score(labels, all_preds)\n",
    "prec = precision_score(labels, all_preds)\n",
    "rec = recall_score(labels, all_preds)\n",
    "f1 = f1_score(labels, all_preds)\n",
    "try:\n",
    "    auc = roc_auc_score(labels, all_probs)\n",
    "except:\n",
    "    auc = float('nan')\n",
    "\n",
    "print(\"\\n🎯 Evaluation Metrics:\")\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"AUROC:     {auc:.4f}\")\n",
    "\n",
    "# === 保存 JSON 结果 ===\n",
    "\n",
    "\n",
    "metrics_path = os.path.join(eval_dir, \"eval_metrics.json\")\n",
    "records_path = os.path.join(eval_dir, \"eval_records.json\")\n",
    "\n",
    "with open(metrics_path, \"w\") as f:\n",
    "    json.dump({\n",
    "        \"Accuracy\": round(acc, 4),\n",
    "        \"Precision\": round(prec, 4),\n",
    "        \"Recall\": round(rec, 4),\n",
    "        \"F1 Score\": round(f1, 4),\n",
    "        \"AUROC\": round(auc, 4)\n",
    "    }, f, indent=4)\n",
    "\n",
    "with open(records_path, \"w\") as f:\n",
    "    json.dump(json_records, f, indent=4)\n",
    "\n",
    "print(f\"\\n📊 Metrics saved to: {metrics_path}\")\n",
    "print(f\"📝 Per-image results saved to: {records_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initial 版本评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tqdm import tqdm  # 使用普通tqdm，仅文本进度条\n",
    "from PIL import Image\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt  # 仅用于保存图表，不显示\n",
    "\n",
    "\n",
    "def build_model(name):\n",
    "    \"\"\"构建指定类型的模型\"\"\"\n",
    "    if name == \"resnet18\":\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "    elif name == \"resnet50\":\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "    elif name == \"efficientnet_b0\":\n",
    "        model = models.efficientnet_b0(pretrained=True)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model: {name}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"模型验证主函数（纯命令行版本）\"\"\"\n",
    "    # === 配置参数（需手动修改路径）===\n",
    "    pseudo_txt = \"/data_lg/keru/project/part2/DermNet/eval/final_test_list.txt\"  # txt测试集路径\n",
    "    model_path = \"/data_lg/keru/project/part2/outputs/best_resnet50.pt\"  # 模型路径\n",
    "    gradcam_dir = \"/data_lg/keru/project/part2/DermNet/eval/eval_initial/gram\"  # Grad-CAM保存目录\n",
    "    eval_dir = \"/data_lg/keru/project/part2/DermNet/eval/eval_initial\"  # 评估结果保存目录\n",
    "    batch_size = 32\n",
    "    model_name = \"resnet50\"\n",
    "\n",
    "    os.makedirs(gradcam_dir, exist_ok=True)\n",
    "    os.makedirs(eval_dir, exist_ok=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"🔥 使用设备: {device}\")\n",
    "\n",
    "    # === 模型加载 ===\n",
    "    model = build_model(model_name).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    print(f\"✅ 模型加载自: {model_path}\")\n",
    "\n",
    "    # === 数据预处理 ===\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ])\n",
    "\n",
    "    # === 从txt读取测试集 ===\n",
    "    samples, labels = [], []\n",
    "    with open(pseudo_txt) as f:\n",
    "        for line in f:\n",
    "            path, lbl = line.strip().split(\"\\t\")\n",
    "            samples.append(path)\n",
    "            labels.append(int(lbl))\n",
    "    print(f\"📊 加载 {len(samples)} 个测试样本\")\n",
    "\n",
    "    # === Grad-CAM设置 ===\n",
    "    target_layer = model.layer4[-1] if 'resnet' in model_name else model.features[-1]\n",
    "    cam = GradCAM(model=model, target_layers=[target_layer])\n",
    "\n",
    "    # === 推理并收集结果 ===\n",
    "    all_preds, all_probs, json_records = [], [], []\n",
    "    correct_samples, wrong_samples = [], []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(enumerate(zip(samples, labels)), total=len(samples), desc=\"推理中\")\n",
    "        for i, (img_path, true_label) in pbar:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            input_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "            outputs = model(input_tensor)\n",
    "            prob = torch.softmax(outputs, dim=1)[:, 1].item()\n",
    "            pred = torch.argmax(outputs, dim=1).item()\n",
    "\n",
    "            all_preds.append(pred)\n",
    "            all_probs.append(prob)\n",
    "            is_correct = (pred == true_label)\n",
    "\n",
    "            # 保存样本信息\n",
    "            sample_info = {\n",
    "                \"img_path\": img_path,\n",
    "                \"true_label\": true_label,\n",
    "                \"pred\": pred,\n",
    "                \"prob\": prob,\n",
    "                \"is_correct\": is_correct\n",
    "            }\n",
    "\n",
    "            if is_correct:\n",
    "                correct_samples.append(sample_info)\n",
    "            else:\n",
    "                wrong_samples.append(sample_info)\n",
    "\n",
    "            json_records.append({\n",
    "                \"img\": img_path,\n",
    "                \"true\": int(true_label),\n",
    "                \"pred\": int(pred),\n",
    "                \"prob\": round(prob, 4),\n",
    "                \"correct\": int(is_correct)\n",
    "            })\n",
    "\n",
    "    # === 随机选择7张正确和7张错误样本 ===\n",
    "    selected_correct = random.sample(correct_samples, min(7, len(correct_samples)))\n",
    "    selected_wrong = random.sample(wrong_samples, min(7, len(wrong_samples)))\n",
    "    selected_samples = selected_correct + selected_wrong\n",
    "    print(f\"🔍 选中 {len(selected_correct)} 正确样本和 {len(selected_wrong)} 错误样本生成Grad-CAM\")\n",
    "\n",
    "    # === 生成并保存Grad-CAM ===\n",
    "    gradcam_results = []\n",
    "    for i, sample in enumerate(selected_samples):\n",
    "        img = Image.open(sample[\"img_path\"]).convert(\"RGB\")\n",
    "        input_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "        # 生成Grad-CAM\n",
    "        target_class = sample[\"pred\"]\n",
    "        targets = [ClassifierOutputTarget(target_class)]\n",
    "        grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0, :]\n",
    "\n",
    "        rgb_image = input_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "        rgb_image = (rgb_image - rgb_image.min()) / (rgb_image.max() - rgb_image.min())\n",
    "        visualization = show_cam_on_image(rgb_image, grayscale_cam, use_rgb=True)\n",
    "\n",
    "        # 保存图像\n",
    "        result_type = \"correct\" if sample[\"is_correct\"] else \"wrong\"\n",
    "        img_name = os.path.basename(sample[\"img_path\"]).split(\".\")[0]\n",
    "        out_name = f\"{result_type}_{i + 1}_{img_name}_gradcam.jpg\"\n",
    "        out_path = os.path.join(gradcam_dir, out_name)\n",
    "        Image.fromarray(visualization).save(out_path)\n",
    "\n",
    "        # 记录Grad-CAM信息\n",
    "        gradcam_results.append({\n",
    "            \"image_path\": sample[\"img_path\"],\n",
    "            \"true_label\": sample[\"true_label\"],\n",
    "            \"predicted_class\": target_class,\n",
    "            \"probability\": sample[\"prob\"],\n",
    "            \"gradcam_path\": out_path,\n",
    "            \"is_correct\": sample[\"is_correct\"]\n",
    "        })\n",
    "\n",
    "        # 仅文本提示，不显示图像\n",
    "        print(f\"\\n📸 已保存 {result_type} 样本 {i+1} 的Grad-CAM: {out_name}\")\n",
    "\n",
    "    # === 计算评估指标 ===\n",
    "    acc = accuracy_score(labels, all_preds)\n",
    "    prec = precision_score(labels, all_preds)\n",
    "    rec = recall_score(labels, all_preds)\n",
    "    f1 = f1_score(labels, all_preds)\n",
    "    try:\n",
    "        auc = roc_auc_score(labels, all_probs)\n",
    "    except:\n",
    "        auc = float('nan')\n",
    "\n",
    "    print(f\"\\n🎯 评估指标:\")\n",
    "    print(f\"  准确率: {acc:.4f}\")\n",
    "    print(f\"  精确率: {prec:.4f}\")\n",
    "    print(f\"  召回率: {rec:.4f}\")\n",
    "    print(f\"  F1分数: {f1:.4f}\")\n",
    "    print(f\"  AUROC: {auc:.4f}\")\n",
    "\n",
    "    # === 保存JSON结果 ===\n",
    "    metrics_path = os.path.join(eval_dir, \"eval_metrics.json\")\n",
    "    records_path = os.path.join(eval_dir, \"eval_records.json\")\n",
    "    gradcam_path = os.path.join(eval_dir, \"gradcam_summary.json\")\n",
    "\n",
    "    with open(metrics_path, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"Accuracy\": round(acc, 4),\n",
    "            \"Precision\": round(prec, 4),\n",
    "            \"Recall\": round(rec, 4),\n",
    "            \"F1 Score\": round(f1, 4),\n",
    "            \"AUROC\": round(auc, 4)\n",
    "        }, f, indent=4)\n",
    "\n",
    "    with open(records_path, \"w\") as f:\n",
    "        json.dump(json_records, f, indent=4)\n",
    "\n",
    "    with open(gradcam_path, \"w\") as f:\n",
    "        json.dump(gradcam_results, f, indent=4)\n",
    "\n",
    "    print(f\"\\n📊 指标保存至: {metrics_path}\")\n",
    "    print(f\"📝 样本记录保存至: {records_path}\")\n",
    "    print(f\"🔥 Grad-CAM汇总保存至: {gradcam_path}\")\n",
    "\n",
    "    # === 生成指标可视化图表（仅保存，不显示）===\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    metrics = [acc, prec, rec, f1, auc]\n",
    "    labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"AUROC\"]\n",
    "    plt.bar(labels, metrics, color=['skyblue', 'lightgreen', 'lightcoral', 'plum', 'lightyellow'])\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.title('模型评估指标')\n",
    "    plt.ylabel('分数')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    metrics_plot = os.path.join(eval_dir, \"metrics_barplot.png\")\n",
    "    plt.savefig(metrics_plot)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"📈 指标图表已保存至: {metrics_plot}\")\n",
    "    print(\"（所有结果可在保存目录中查看）\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1:1 positive & negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo test list saved to /data_lg/keru/project/part2/DermNet/eval/final_test_list_ratio.txt\n",
      "Acne: 312, Non-Acne: 312\n",
      "正负样本比例: 312:312 = 1:1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# === 配置 ===\n",
    "train_root = \"/data_lg/keru/project/part2/DermNet/test\"\n",
    "output_txt = \"/data_lg/keru/project/part2/DermNet/eval/final_test_list_ratio.txt\"\n",
    "random_seed = 42  # 设置随机种子，保证结果可复现\n",
    "\n",
    "# 设置随机种子\n",
    "random.seed(random_seed)\n",
    "\n",
    "# === 找到所有子文件夹 ===\n",
    "all_classes = [\n",
    "    d for d in os.listdir(train_root)\n",
    "    if os.path.isdir(os.path.join(train_root, d))\n",
    "]\n",
    "\n",
    "# Acne 类和 Non-Acne 类分开\n",
    "acne_folders = [d for d in all_classes if \"acne\" in d.lower()]\n",
    "non_acne_folders = [d for d in all_classes if d not in acne_folders]\n",
    "\n",
    "assert acne_folders, \"没有找到包含 'acne' 的文件夹！\"\n",
    "\n",
    "# === 收集所有 Acne 样本 ===\n",
    "acne_samples = []\n",
    "for folder in acne_folders:\n",
    "    folder_path = os.path.join(train_root, folder)\n",
    "    imgs = [os.path.join(folder_path, f) for f in os.listdir(folder_path)\n",
    "            if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "    acne_samples.extend(imgs)\n",
    "\n",
    "# === 收集所有 Non-Acne 样本 ===\n",
    "non_acne_samples = []\n",
    "for folder in non_acne_folders:\n",
    "    folder_path = os.path.join(train_root, folder)\n",
    "    imgs = [os.path.join(folder_path, f) for f in os.listdir(folder_path)\n",
    "            if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "    non_acne_samples.extend(imgs)\n",
    "\n",
    "# === 随机选择与Acne样本数量相同的Non-Acne样本 ===\n",
    "num_acne = len(acne_samples)\n",
    "num_non_acne = len(non_acne_samples)\n",
    "\n",
    "if num_non_acne >= num_acne:\n",
    "    # 如果Non-Acne样本数量足够，随机选择与Acne相同数量的样本\n",
    "    selected_non_acne = random.sample(non_acne_samples, num_acne)\n",
    "else:\n",
    "    # 如果Non-Acne样本数量不足，使用全部Non-Acne样本并对其进行重复采样\n",
    "    print(f\"警告: Non-Acne样本数量({num_non_acne})少于Acne样本数量({num_acne})，将进行重复采样\")\n",
    "    selected_non_acne = random.choices(non_acne_samples, k=num_acne)\n",
    "\n",
    "# === 合并 & 保存 txt ===\n",
    "with open(output_txt, \"w\") as f:\n",
    "    # 写入Acne样本\n",
    "    for p in acne_samples:\n",
    "        f.write(f\"{p}\\t1\\n\")\n",
    "    # 写入随机选择的Non-Acne样本\n",
    "    for p in selected_non_acne:\n",
    "        f.write(f\"{p}\\t0\\n\")\n",
    "\n",
    "print(f\"Pseudo test list saved to {output_txt}\")\n",
    "print(f\"Acne: {len(acne_samples)}, Non-Acne: {len(selected_non_acne)}\")\n",
    "print(f\"正负样本比例: {len(acne_samples)}:{len(selected_non_acne)} = 1:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CFLD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
